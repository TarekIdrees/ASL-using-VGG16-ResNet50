{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_VGG16&Net50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Set up colab for ASL data from kaggel**"
      ],
      "metadata": {
        "id": "3zqo5Ua0bsLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "Y4Fcg7K_gcYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "6G1YMwBhglA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "_JDvtRDWgn6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vnlJ5LCkVX1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download grassknoted/asl-alphabet"
      ],
      "metadata": {
        "id": "f68eq3AgVsbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip asl-alphabet.zip"
      ],
      "metadata": {
        "id": "bfFFY6IMWMzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import needed libraries**"
      ],
      "metadata": {
        "id": "MUeGgdP4b2RC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POMNZFi9gHxa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import cv2\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.metrics import AUC\n",
        "from keras.metrics import Precision\n",
        "from keras.metrics import Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'asl_alphabet_train//asl_alphabet_train'\n",
        "test_dir = 'asl_alphabet_test//asl_alphabet_test'\n",
        "labels_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11,\n",
        "               'M': 12,\n",
        "               'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23,\n",
        "               'Y': 24,\n",
        "               'Z': 25, 'space': 26, 'del': 27, 'nothing': 28}"
      ],
      "metadata": {
        "id": "rrOjUDJqbGh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data():\n",
        "    Y_train = []\n",
        "    X_train = []\n",
        "    size = 64, 64\n",
        "    print(\"LOADING DATA FROM : \", end=\"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end=' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "            # read image\n",
        "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image,0)\n",
        "            # resize image\n",
        "            temp_img = cv2.resize(temp_img, size)\n",
        "            #load converted classes\n",
        "            Y_train.append(labels_dict[folder])\n",
        "            X_train.append(temp_img)\n",
        "    #convert X_train to numpy\n",
        "    X_train = np.array(X_train)\n",
        "    #normalize pixels of X_train\n",
        "    X_train = X_train.astype('float32')/255.0\n",
        "    #convert from 1-channel to 3-channel\n",
        "    X_train = np.stack((X_train,)*3, axis=-1)\n",
        "    #convert Y_train to numpy\n",
        "    Y_train = np.array(Y_train)\n",
        "    print()\n",
        "    print(\"Pixels after normalize : min = %d max = %d \"%(X_train.min(),X_train.max()))\n",
        "    print('Loaded', len(X_train), 'images for training,', 'Train data shape =', X_train.shape)\n",
        "\n",
        "    return X_train, Y_train\n"
      ],
      "metadata": {
        "id": "PnR3WaiwWmRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data():\n",
        "    labels = []\n",
        "    X_test = []\n",
        "    size = 64, 64\n",
        "    for image in os.listdir(test_dir):\n",
        "        # read image\n",
        "        temp_img = cv2.imread(test_dir + '/'+ image,0)\n",
        "        # resize image\n",
        "        temp_img = cv2.resize(temp_img, size)\n",
        "        # load converted classes\n",
        "        labels.append(labels_dict[image.split('_')[0]])\n",
        "        X_test.append(temp_img)\n",
        "    #convert X_test to numpy\n",
        "    X_test = np.array(X_test)\n",
        "    #normalize pixels of X_test\n",
        "    X_test = X_test.astype('float32')/255.0\n",
        "    #convert from 1-channel to 3-channel in Gray\n",
        "    X_test = np.stack((X_test,)*3, axis=-1)\n",
        "    #convert Y_test to numpy\n",
        "    Y_test = np.array(labels)\n",
        "    print(\"Pixels after normalize : min = %d max = %d \"%(X_test.min(),X_test.max()))\n",
        "    print('Loaded', len(X_test), 'images for testing,', 'Test data shape =', X_test.shape)\n",
        "\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "Wesb58lacCT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data in Gray**"
      ],
      "metadata": {
        "id": "beHgwQkY9Hz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train =  load_train_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK-DK9fUXG8I",
        "outputId": "062579be-bcb4-4a86-9fbb-44e43653cefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING DATA FROM : B | W | L | space | H | K | S | nothing | M | A | P | R | Q | E | Z | U | V | O | J | X | C | T | Y | D | N | del | I | G | F | \n",
            "Pixels after normalize : min = 0 max = 1 \n",
            "Loaded 87000 images for training, Train data shape = (87000, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test = load_test_data()"
      ],
      "metadata": {
        "id": "Tw7usPKNCsYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571fb537-5145-4e62-c047-d1db87bc93ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixels after normalize : min = 0 max = 1 \n",
            "Loaded 29 images for testing, Test data shape = (29, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing: One-hot enconding the data**"
      ],
      "metadata": {
        "id": "ZkH2sPEU9LnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Y_train befor one-hot encoder : \",Y_train[0])\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n",
        "print(\"Y_train befor one-hot encoder : \",Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGMMSfbQKDLf",
        "outputId": "aab53684-7825-4fb4-9780-733fcc5c7814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_train befor one-hot encoder :  1\n",
            "Y_train befor one-hot encoder :  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print('Loaded', len(Y_test), 'images for testing,', 'Test data shape =', Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHhfLAnYAg4T",
        "outputId": "79dd9bb3-fb83-40ea-b183-156b87f346b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 29 images for testing, Test data shape = (29, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data augmentation**"
      ],
      "metadata": {
        "id": "9OaR3xY69hQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False )\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "9l8aFYkqV45P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note: number of class equal to 29 but the data in kaggel in test folder equal to 28 so you have to add manually the del_photo to test folder. "
      ],
      "metadata": {
        "id": "GUJ4gAEL-GoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create VGG16 model**"
      ],
      "metadata": {
        "id": "-8E0YOxt9rYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(VGG16(weights='imagenet', include_top=False, input_shape=(64,64,3)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(420, activation='relu')) \n",
        "\n",
        "model.add(Dense(29, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[AUC(name = 'Accuracy'),Precision(name = 'Precision'),Recall(name = 'Recall')] )#optimizer = sigmoed\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmjrVnezMLK8",
        "outputId": "4c146f9f-27dd-4fbb-8949-132f79ce4f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 420)               860580    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                12209     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,587,477\n",
            "Trainable params: 15,587,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create ResNet50 Model**"
      ],
      "metadata": {
        "id": "86twoedb9zoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_RES = Sequential()\n",
        "\n",
        "model_RES.add(ResNet50(input_shape= (64,64,3),include_top=False,weights='imagenet'))\n",
        "\n",
        "model_RES.add(Flatten())\n",
        "\n",
        "model_RES.add(Dense(420, activation='relu'))\n",
        "\n",
        "model_RES.add(Dense(29, activation='softmax'))\n",
        "\n",
        "model_RES.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[AUC(name = 'Accuracy'),Precision(name = 'Precision'),Recall(name = 'Recall')] )\n",
        "\n",
        "model_RES.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKYhVq6iNWsO",
        "outputId": "5f06d635-d25e-4cf7-f4d7-4008b730feb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 4s 0us/step\n",
            "94781440/94765736 [==============================] - 4s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2, 2, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 420)               3441060   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                12209     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,040,981\n",
            "Trainable params: 26,987,861\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit VGG16 model with 2 epochs**"
      ],
      "metadata": {
        "id": "IO4oj0Tj94s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "history = model.fit(datagen.flow(X_train,Y_train, batch_size = 64) ,epochs = 2 , validation_data = (X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dos2tqkm8mdu",
        "outputId": "8986e2ed-22a4-4ca5-ff4c-4166b872bdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1360/1360 [==============================] - 13750s 10s/step - loss: 0.3329 - Accuracy: 0.9965 - Precision: 0.9662 - Recall: 0.8749 - val_loss: 1.5314e-04 - val_Accuracy: 1.0000 - val_Precision: 1.0000 - val_Recall: 1.0000\n",
            "Epoch 2/2\n",
            " 406/1360 [=======>......................] - ETA: 2:41:15 - loss: 0.0268 - Accuracy: 0.9998 - Precision: 0.9932 - Recall: 0.9910"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit ResNet50 with 1 epochs**"
      ],
      "metadata": {
        "id": "17dFvmJe9-yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "history_2 = model_RES.fit(datagen.flow(X_train,Y_train, batch_size = 64) ,epochs = 1 , validation_data = (X_test, Y_test))"
      ],
      "metadata": {
        "id": "29uFZc0POAdM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e132221-d308-4c26-9aed-ad91a3ef1be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1360/1360 [==============================] - 12975s 10s/step - loss: 0.2667 - Accuracy: 0.9964 - Precision: 0.9612 - Recall: 0.9014 - val_loss: 0.0039 - val_Accuracy: 1.0000 - val_Precision: 1.0000 - val_Recall: 1.0000\n"
          ]
        }
      ]
    }
  ]
}